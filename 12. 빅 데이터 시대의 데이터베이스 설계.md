# 12.3 웹 서비스 및 데이터 모델링

## 데이터 모델링의 중요성을 알자
데이터 모델링
- 비지니스 로직에서 필요한 '데이터 항목' 들을 뽑아내고, 데이터 항목 간 관계성을 부여하여 모순이 없도록 설계한다.
    - ERD : Entitiy (데이터 항목) Relation (관계성) Diagram
- 내가 만드려는 서비스의 비지니스로직에 '어떤 데이터가 필요한가'를 고민하여 테이블 설계에 반영하는 방법론

웹 어플리케이션을 만들 때, 어떤 데이터를 다루고 그것들이 어떤 관계에 있는지를 밝혀내는 것은 중요하다.

NoSQL 중에는 키/값 2가지 요소만 가지는 것이 있다. 값에 임의의 데이터 타입을 넣을 수 있고, 들어가는 데이터 항목의 형식도 변경 가능하다.
하지만 이러한 NoSQL에서도 value에 어떤 데이터 타입이던지 다 때려 박는다고 해서 value 안에 어떤 데이터들이 들어가는지 안중요한 게 아니다. 
NoSQL 의 경우에는 모델링이 필요없다고 생각할 수 있지만, 데이터 모델링 자체는 꼭 필요하다. 구현하는 방법의 차이일 뿐이다


## 데이터 분류
데이터 항목에는 한번 등록되면 자주 변경되지 않는 타입, 자주 변경/추가되는 타입이 있다.
전자를 마스터 데이터, 후자를 트랜잭션 데이터 라고 한다.
마스터 데이터의 예로는 store DB 의 상품 테이블의 데이터, 트랜잭션 데이터로는 결제정보 테이블 데이터를 들 수 있다.
마스터 데이터는 주로 서비스 운영측에 의해 관리되고, 트랜잭션 데이터는 유저의 행동에 의해 변화한다.

사용자 정보는 모든 게임에서 사용하는 공통적인 것 (별명 등) 이 있고 각 게임 고유의 것이 있다 (유저 별 소유 아이템).
별명은 User ID 가 같으면 어떤 게임에서든 똑같고, 유저 별 소유 아이템정보는 게임마다 다를 수 있다.
공통적인 것은 공통 테이블에, 게임 고유의 것은 각 게임관련 테이블에 저장해야 한다.
게임 공통정보는 마스터 데이터의 측면이 강하고 게임 고유의 상태는 트랜잭션 데이터로서의 성질을 갖는다.

## 마스터계의 테이블
전체 레코드 수가 그다지 많지 않다.

## 트랜잭션계의 테이블
이러한 테이블의 레코드 수는 인기 서비스에서는 방대하다.
예를 들어 사용자 수가 천 만명이고 한 명당 100개의 아이템을 소유하고 있다면 그 테이블은 10억 레코드나 된다.
이러한 테이블은 인덱스 설계는 물론 데이터 포맷 등도 최적화해야한다.
본질적으로 중요한 것은 '무리하지 않는 범위에서 부담 없는 사양으로 하는 것'이다.

데이터의 범위를 제한함으로써 레코드수의 상단을 조정할 수도 있다, 예를 들어 사용자당 소유 아이템 수를 20개로 제한한다던가 할 수 있다.
이러한 제한은 어플리케이션의 성격이나 특색이 될 수도 있으므로 자신이 서비스 기획자가 된 것 같은 기분으로 생각해보는 것이 좋다.

## 테이블 관련
테이블은 각각 독립적인 것이 아니라 상호관계를 가지고 있다. 
대규모 웹 서비스의 경우 테이블을 여러 서버 로 분할하기 쉽게 하기 위해 조인을 사용하지 않는 경향이 있지만, 조인을 사용하지 않아도 논리적으로 테이블 간에 관계를 가지고 있는 경우가 많다.

### 일대다 관계
가장 표준적 형태.

### 파생 관계
아이템 - 소비아이템, 공격아이템, 방어아이템

![캡처](https://github.com/dudwhd93/TIL/blob/main/%EC%8A%88%ED%8D%BC-%EC%84%9C%EB%B8%8C%ED%83%80%EC%9E%85%20%EA%B4%80%EA%B3%84.PNG)

### 계층 관계
미션 A를 클리어하면 미션 B가 출현, B 다음 D, ...
하위에 대해 상위는 0..1개, 상위에 대해 하위는 0..N개 의 구조를 같는다. tree 형태를 말하는 것으로 보임.
계층 관계 데이터는 무한 루프에 빠질 수 있으므로 등록 오류를 방지하기 위해 계층 구분을 도입할 수 있다.

### 계층형 부품표 타입
피라미드형의 계층 관계의 약점을 극복하는 모델


# 12.4 데이터 양 증가 대책과 고속화 수법

## 테이블 사이즈와 부하 대책
대형 웹 서비스에서는 데이터가 빠르게 쌓이기 때문에 테이블 사이즈에 따른 부하 대책을 강구해야한다.
여기에서는 특히 대용량 데이터를 다룬다는 관점에서 각 테이블의 성질에 대한 대책을 고찰하고자 한다.
즉 대용량 데이터를 다루는 서비스를 개발하기 위해 DB의 테이블 관점에서 어떤 대책을 강구해야하는지를 고민해본다.

문제의 진행 과정 : 사용자 수 급증 -> 데이터양 증가 -> 성능문제 표면화
발생할 수 있는 문제
- 적절한 인덱스가 사용되지 않아 전체 테이블스캔을 하는 문제가 발생한다.
- 특정 테이블의 데이터양이 적을 때는 해당 테이블의 인덱스 전체가 메모리 안에서 처리될 수 있었는데, 테이블 사이즈가 커지면서 인덱스 전체 크기가 메모리 크기를 초과하면서 디스크 엑세스가 발생하게 되는 문제가 생겨난다.
- UPDATE, DELETE 작업도 갱신 대상 레코드를 찾기 위해 읽기 작업을 하며, INSERT 는 추가하려는 레코드가 속한 인덱스 블록을 읽어오기 위해 로드 처리가 필요하다. 따라서 갱신 쿼리들도 성능 문제가 발생한다.

참조 트래픽에 대한 부하 대책 : 상대적으로 쉽다.
- 슬레이브 추가하여 엑세스를 분산
- memcached 와 같은 캐시서버 추가

갱신 처리를 위한 부하 대책 : 상대적으로 어렵다.
- 데이터를 보유한 모든 서버에 갱신할 수 밖에 없어 어렵다.
- 대용량 데이터베이스의 테이블 설계에 있어 갱신처리에 초점을 맞춰 부하대책을 강구한다.


### INSERT 주체의 테이블
SELECT 쿼리 수행 수가 매우 적고 INSERT 만 계속 수행하는 '이력계 테이블'에는 인덱스를 추가하지 않는게 좋다.
SELECT 빈도가 나름 높다면 인덱스가 필요하다. 웹 서비스라면 사용자 ID 에 인덱스가 필요한 경우가 대부분이다.
이런 이력계 테이블에서는 사용자 ID에 대해 임의에 가까운 순서로 레코드가 들어가기 때문에 사용자 ID의 인덱스는 단편화 되기 쉽고 사용자 ID 전역에 대한 엑세스가 발생한다.
레코드 수가 적을 때는 메모리 내에서 인덱스에 대한 처리가 완결됨. 레코드 수가 늘어나면 인덱스 크기가 커지면서 메모리 안에서 인덱스를 처리할 수 없게 된다.
갱신 대상의 인덱스를 로드하기 위해 디스크 I/O가 발생하고 성능 저하가 일어난다.
갑자기 사용자수가 늘면서 데이터가 늘어나면 이런 문제가 발생할 수 있다.

* 인덱스 단편화란?
B-Tree 인덱스는 Leaf 페이지로 데이터를 찾아 들어가는 과정에서 Random Disk Access 가 필요하다. 이때 물리적인 디스크에 순차적으로 데이터가 있다면 더 나은 성능을 보이지만, 그렇지 않은 경우엔 성능저하가 발생하며 이를 단편화 라고 한다.
단편화 발생시 Range Scan 이나 Full Index Scan 시 더 많은 시간이 소요된다.


### INSERT의 성능 지표
메모리 내에서 INSERT가 완결되고 있던 것이 디스크 I/O가 발생하게 됨으로써 어느 정도의 성능저하가 발생하는지를 지표로서 파악해두는 것이 중요하다.
메모리 내에서의 INSERT 는 대략 초당 10,000건 정도. 복제 대상 슬레이브는 단일 스레드 갱신계 SQL 문 실행한다. 이 슬레이브에서도 이정도의 INSERT 는 가능하다.
인덱스 사이즈가 메모리 사이즈(버퍼 풀 사이즈)를 초과하여 디스크 엑세스가 발생하면 초당 INSERT 성능은 크게 저하된다.
InnoDB는 Insert Buffering 이라는 자체 최적화 메커니즘이 있음에도 초당 2000 INSERT 로 떨어진다.
HDD 를 SSD 로 바꾸면 어느정도 성능개선이 있을까? 좋아지는 것은 사실이지만 그래봐야 초당 5000 INSERT 로 좋아진다.
즉, INSERT 를 고속화하기 위해서는 뭐니뭐니해도 메모리 안에서 완결하는 것이 중요하다. 이를 실현하기 위해 인덱스 크기를 작게 하는것이 필요하다.
INSERT 주체 테이블은 이력계 데이터를 메인으로 취급하는 경향이 있기 때문에 이를 잘 이용하면 메모리 내에서 INSERT 를 완결하는 것도 불가능하지 않다.
- 즉, SELECT 가 별로 발생하지않고 INSERT 가 주로 발생하면, 인덱스를 최소한으로 가져가면서 메모리 안에서 인덱스 처리를 완결하도록 해야한다.

### 시계열 처리의 고속화 접근
시계열처리를 고속화하기 위해 가장 추천되는 것이 날짜로 레인지 파티션을 구성하기 라는 것이다.
레인지 파티션 : 테이블을 물리적으로 분할하면서도 어플리케이션에서는 논리적으로 하나의 테이블로 보여주는 것.
INSERT가 시계열로 들어가는 한 이 INSERT 시에 조작되는 인덱스는 최신 파티션 인덱스로 한정된다. 따라서 파티션 크기가 한정되어 있다면 메모리에 로드되는 인덱스도 아주 소규모에 불과하다. 따라서 INDEX 성능을 크게 끌어올릴 수 있다.

레인지 파티셔닝으로 액티브한 인덱스 사이즈를 작게 만들기
- 모든 인덱스가 메모리 안으로 들어가면 INSERT 는 고속
- 순차적으로 투입되는 열에 파티셔닝 (작성시간 또는 SURROGATE KEY)
- 인덱스는 파티션 마다 만들어진다
- 전체 고유성을 보장하기 위해 파티션의 키는 기본 키의 일부임이 조건
- 과거 데이터에 엑세스하지 않으면 최근 파티션에 속한 인덱스만 캐싱된다.

레인지 파티셔닝 이외에 인덱스 크기를 작게할 수 있는 방법
- 테이블을 날짜/시간별로 분할하기
- 과거 데이터를 삭제하거나 다른 서버로 옮기기
- 인덱스를 만들지 않기
- 불필요한 열을 만들지 않기
- 공간 효율적인 데이터형 사용하기
- 대용량 메모리 탑재하기


## DELETE의 튜닝

### 데이터의 보존기간 확인하기
테이블 사이즈를 작게 유지하는 것이 메모리 내에서 빠르게 INSERT 하기 위해 중요하다고 했다.
이를 위한 쉬운 방법이 테이블에서 주기적으로 데이터를 지우는 것.
업무적으로 또는 법적으로 삭제하면 안되는 데이터는 주기적으로 AWS Glacier (아카이브용 데이터 저장소) 로 옮긴다.
(필요할 때 다소 시간이 걸리더라도 다시 찾아볼 수 있는 안전한 저장소)


### 데이터 제거 방식에 따라 성과는 변화한다
조건부 제거 프로세스 (예를 들어 특정 사용자 데이터 삭제와 같은 것)은 용량면이나 성능면에서 즉시 큰 효과를 거둘 수는 없지만 중장기적으로는 효과를 얻을 수 있다.
데이터베이스의 I/O 단위는 16KB 와 같이 정해진 단위의 블록으로 되어있다.
한 레코드 당 크기는 블록크기보다 작으므로 조건부로 레코드 삭제시 그 블록의 전체 레코드를 삭제하는 것이 아니면 물리적으로 블록을 제거할 수 없다.
레코드 수가 줄어도 결국 블록의 수가 줄지 않으면 총 데이터크기는 줄어들지 않는다.
이 상태에서 데이터 크기를 줄이는 방법은 MySQL OPTIMIZE TABLE 과 같이 테이블을 재구성하는 방법이다.

실제 운영중 MySQL OPTIMIZE TABLE 를 할 수 없더라도 조건부 제거 프로세스를 진행하는 게 그래도 좋다.
블록의 대부분이 벌레먹은 상태가 되어 물리적으로 제거되지 못했다고 해도, 다음에 INSERT 가 들어오면 새 블록을 생성하지 않고 벌레먹은 부분을 채우기 때문에 테이블 크기 증가속도를 제어해준다.

### 슬레이브 지연을 방지하려면
MySQL과 같이 싱글 스레드 기반의 복제 메커니즘에서는 DELETE 에 따라 많은 양의 레코드를 삭제할 때 복제 지연이 일어나지 않도록 주의해야한다.
DELETE 는 상상이상으로 무거운 처리이다.
실제 레코드 삭제 뿐 아니라 인덱스에서도 삭제해야해서 오래 걸린다.
DELETE 대상 레코드는 재부분 오랜 기간 엑세스하지 않은 버퍼 풀에 올라와있지 않은 데이터일 확률이 크므로 높은 확률로 디스크 엑세스가 발생한다.

복제지연을 일으키지 않게 DELETE 하는 수단으로 해당 슬레이브에서 삭제대상 레코드를 미리 SELECT 해둬서 메모리에 올려놓는 방법이 있다.
실제 레코드뿐만 아니라 인덱스도 읽어두면 디스크 엑세스를 더 낮출 수 있다.
또한 MySQL 5.5 이상에서는 DELETE/UPDATE 시 인덱스 갱신을 비동기적으로 수행하는 메커니즘인 Change Buffering 기능을 제공한다.
대량 레코드 삭제시 10배 이상 빨라진다는 벤치마크 결과가 있다.

## UPDATE 주체의 테이블
소셜미디어 서비스에서의 친구와의 정보 업데이트 (소셜 그래프 업데이트) 와 같은 처리를 담당하는 테이블은 업데이트 작업이 압도적으로 많이 일어난다.
UPDATE 실행을 위해서는 갱신 대상 레코드(블록)을 메모리에 읽어와야한다. 이 과정에서 데이터가 많아 메모리 내에서의 접근이 안되면 디스크 엑세스가 발생한다.
UPDATE 는 DELETE 처럼 논리적 처리를 비동기로 돌리거나 할 수 없다.
사용자 측면에서 동기적으로 실시해야만 한다.
UPDATE 는 메모리 내에서 라면 싱글 스레드에서 초당 12000회 가능.
디스크 엑세스시 초당 300회 가능.
디스크 I/O 빈발하는 경우에 대책은 SSD 로의 교체, 메모리 용량 증가 등이 있다.

관리자 측면에서 할 수 있는 것으로 InnoDB Plugin 을 사용하는 것, 커밋시에 디스크와 파일 시스템 캐시로의 쓰기를 그만두는 innodb_flush_log_at_trx_commit=0 설정하기, 버퍼 풀 사이즈를 메모리 크기 한계 까지 끌어올리기 등이 있다.

참고) InnoDB Plugin을 사용하는 경우 Built-in InnoDB에 추가되지 않은 몇 가지 신기능을 사용할 수도 있고, 성능 향상도 기대할 수 있다.


## 부하 경향 모니터링하기
서비스 기동 후 트래픽이 어떻게 변화해나가는지를 지속적으로 모니터링 해야한다. 위기의 사전 감지 뿐 아니라 이 시스템이 앞으로 얼마나 트래픽을 감당할 수 있는지를 파악할 수 있다.
이를 위한 효과적인 지표로서 '갱신 빈도', '병렬도' 를 들 수 있다.

갱신 빈도
- 복제 지연을 막을 수 있는지 여부 파악을 위한 지표. 초당 UPDATE 횟수, InnoDB 내부의 레코드 갱신 횟수가 중요지표가 된다.
- 슬레이브의 처리 능력 이상의 갱신이 마스터로 부터 오는 경우 지연발생. 슬레이브가 현 시점 어느정도까지 커버가능한지 확인해야함.
- 슬레이브가 커버 가능한 수준과 마스터에 행해지는 갱신 빈도를 비교해서 얼마나 버틸 수 있는지를 파악해야함.

병렬도
- 몇 개의 스레드가 클라이언트로부터 요청을 처리하고 있는지를 나타냄
- thread_running 이라는 MySQL 상태변수 값으로 알 수 있음. 취득 순간의 스냅샷 값이므로 평균을 측정해서 사용해야함.
- 병렬도와 처리량에는 강한 상관 관계가 있고, 이를 Scailability Law 라는 공식으로 나타냄.
- 병렬도 상승하면 처리량 증가하지만 병렬도가 너무 높으면 반대로 처리량이 내려감.



# 12.5 MySQL의 성능 개선 테크닉

## 쿼리 개선하기
### 느린 쿼리 밝혀내기
슬로우 쿼리 로그, SHOW FULL PROCESSLIST 등의 방법으로 느린 쿼리를 확인할 수 있다.
대다수는 I/O를 다수 발생시키고 있으므로 이 I/O를 얼마나 개선하느냐가 중요 포인트.

I/O 튜닝방법
- 쿼리를 실행시키지 않기
- I/O를 시키지 않기
- 필요한 레코드만 I/O시키기
- 많은 I/O가 필요한 경우 순차적 I/O에 귀착시키기
- 정렬을 시키지 않기
- 병렬 I/O를 시키기 (주로 배치 처리)

2,3 번은 전체 테이블 스캔하고 있는 것을 인덱스 검색으로 귀착시키는 방법이다.
4번은 수천개의 범윙서 레코드를 검색하는 경우 효과적.
웹서비스에서는 수천개를 검색해도 결국 10개 정도 레코드로 한정된다.일치하는 수백개의 레코드를 개별적으로 랜덤 엑세스해나가는 것이 아니라, 인덱스를 스캔하는 것만으로 대상 레코드를 검색한 후에 되돌려주어야할 레코드만을 랜덤 엑세스하는 것이 효과적이다.



### 정렬의 실행 효율에 주의하기
정렬이 정말 필요한지의 여부를 잘 생각하고 사용하자.
정렬 및 LIMIT 은 옵티마이저가 판단을 잘못할 수 있으므로 주의해야한다.

옵티마이저가 판단 잘못하는 예
- 효율이 나쁜 인덱스를 선택하는 경우 : 옵티마이저는 비용 기반이므로 인덱스 선택시 성능측면에선 비효율적인 인덱스를 선택할 수 있다.
- 인덱스의 내용을 올바로 사용하지 않은 경우 : 버그!

### 실행 빈도가 많은 쿼리 밝혀내기
서버 내의 쿼리 총 실행시간 : 쿼리당 평균 실행시간 X 실행 횟수 이다.
느린 쿼리 외에도 빠른 쿼리도 실행 횟수가 너무 많으면 문제가 된다.
빠르다 하더라도 빈도가 과도한 쿼리의 전형적 예가 1+N 형의 쿼리이다.
- 어떤 조건에 맞는 결과를 먼저 확인하여 그것이 100건인 경우에 1건씩 정중히 select 문으로 반환하는 쿼리방법
- https://incheol-jung.gitbook.io/docs/q-and-a/spring/n+1

### 느린 트랜잭션 개선하기
실행에 시간이 오래 걸리는 트랜잭션을 파악하고 싶다.
어떤 트랜잭션이 레코드를 30초 동안 잠그고 있다면 동일 레코드를 잠그고자 하는 트랜잭션은 최대 30초 동안 기다려야 한다.
문재해결을 위해서는 잠금을 오래 유지하는 트랜잭션이 어떤 처리를 하고 있었는지 파악해야한다.
실행에 시간이 오래 걸리는 트랜잭션을 특정하는 것은 매우 어렵다.

필자는 책을 쓸 시점에는 MySlowTranCapture 라는 전용도구를 이용하여 느린 트랜잭션을 파악한다.
네트워크 패킷을 캡처하고 각 클라이언트 트랜잭션의 시작,종료 시간의 차이가 일정 시간 이상인 것들만 로그로 기록하는 툴이다.


### 경쟁에서의 배려
동일 테이블에 다수 클라이언트의 엑세스가 동시에 발생할 수 있다. 이 경우에 잠금 경합이 발생할 수 있다.
예를 들어 소셜 게임에서 어떤 매니아 유저에 대한 엑세스가 쇄도할 수 있다.
매니아 유저 A 에 배틀을 거는 사용자가 많으면 그 사용자 데이터의 레코드 행에 배타 잠긍을 거는 쿼리가 매우 많아진다(UPDATE 및 SELECT FOR UPDATE)행 잠금 메커니즘에 의해 동시 엑세스는 배타제어 되기 때문에 잠금 경쟁이 된다.
잠금 경쟁에 의한 오류를 줄이기 위해 조치를 취해야한다.

#### 타임 아웃 설정
잠금 대기 최대 시간은 innodb_lock_wait_timeout 이다. 디폴트는 50초이다.
웹 서비스에서는 2~5초 정도의 작은 값을 유지하는게 옳다.

#### 잠금을 장시간 걸지 않기
잠금은 트랜잭션 종료에 의해 해제된다. 잠금을 보유하는 시간을 최소화 해야한다.
어떤 작업이 장시간 잠금을 유발할 것인지를 잘 파악해야한다.
잠금 상태에서 외부 네트워크에 엑세스 등은 피해야 한다.
데이터베이스 서버가 여러 대로 분산되어 있다면 잠금을 건 상태에서 외부 네트워크에 엑세스할 가능성이 크다. 이런 상황에서도 잠금 시간을 줄이기 위해 잠금 확보 전 네트워크 엑세스를 마치고 필요한 잠금을 걸어 처리하면 효과적이다.

#### 서로 다른 서버 간의 교착 상태에 주의하기
잠금 대기가 더 심각하게 되는 것이 다른 마스터에 걸쳐 교착 상태가 발생하는 것이다.

시나리오
1. client A : DB1에서 id=100을 잠금
2. client B : DB2에서 id=200을 잠금
3. client A : DB2에서 id=200을 잠금 -> 대기
2. client B : DB1에서 id=100을 잠금 -> 대기

서비스 규모가 커지고 복수의 인스턴스에 동시 갱신해 나가는 사례가 늘면 복수 서버간 교착상태가 자주 발생할 수 있다.
InnoDB 는 교착상태 감지 메커니즘을 갖고 있지만, 여러 서버간 교착상태는 감지해주지 못한다.
위 예에서 2개의 클라이언트는 timeout 걸릴 때 까지 서로 잠금 대기상태가 된다.

서로 다른 서버간 교착상태는 실제로 일어나는지를 확인하는 것이 매우 어려워 MySQL 트러블 슈팅 중에서도 상당한 난이도를 가진 부류이다.
필자는 이러한 현상의 발견을 위해 어플리케이션에서 사용중인 모든 마스터에 MySlowTrancapture 를 사용하여 오래 걸리는 트랜잭션을 추적하여 분석하고 있다.
여러 서버간의 동일 시간에 동일 id 로 대기 상태가 되어 있는 것이 있으면 그것이 교착상태를 일으킨다고 추측할 수 있다.

원칙적으로 교착상태를 방지하기 위해 중요한 것은 잠금 순서를 통일하는 것 이다.
예를 들어, A 와 B가 아이템을 교환하는 과정에서 USER_ITEM 테이블의 A 레코드와 B 레코드를 갱신할 것이다.
이때 어떤 때는 A->B 순서로, 어떤 때는 B->A 순서로 갱신을 처리하면 교착상태가 발생할 확률이 커진다.
이런 문제를 방지하기 위해 사용자 ID 의 오름차순으로 잠금을 걸 수 있도록 통일하는 것이 효과적이다.
레코드 간 잠금 순서 통일 뿐만 아니라, 여러 테이블 갱신작업을 할 때 테이블 간 잠금 순서도 통일해야한다.

SELECT FOR UPDATE 는 배타적 잠금을 보유하기 때문에 괴도하게 사용하면 잠금 경합의 온상이 된다. 















